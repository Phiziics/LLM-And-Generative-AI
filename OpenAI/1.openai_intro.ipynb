{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8374a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from web_scraper import fetch_website_contents\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98847d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Checking the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4a6d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy.\n",
    "\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1a77fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Hello, GPT! This is my first ever message to you! Hi!'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aabeb525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing open ai\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11822b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d760c657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! Welcome — great to meet you. I’m here to help with questions, writing, learning new topics, planning, coding, and lots of other things.\\n\\nWhat would you like to do today? If you’re not sure, here are some ideas:\\n- Explain something simple or hard (in plain language or with examples)\\n- Help draft an email, essay, or message\\n- Brainstorm ideas or plan a project\\n- Solve a math problem or explain concepts\\n- Learn about a topic (science, history, tech, etc.)\\n- Get coding help or debugging tips\\n- Translate or summarize text\\n- Play a quick game or tell a joke\\n\\nTell me your goal or just say “surprise me,” and I’ll tailor my reply.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dde197",
   "metadata": {},
   "source": [
    "Extract details from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2d5ba5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Are Large Language Models (LLMs)? | IBM \n",
      "\n",
      "What are large language models (LLMs)?\n",
      "Machine learning\n",
      "Welcome\n",
      "Caret right\n",
      "Introduction\n",
      "Overview\n",
      "Machine learning types\n",
      "Machine learning algorithms\n",
      "Caret right\n",
      "Data science for machine learning\n",
      "Statistical machine learning\n",
      "Linear algebra for machine learning\n",
      "Uncertainty quantification\n",
      "Bias variance tradeoff\n",
      "Bayesian Statistics\n",
      "Caret right\n",
      "Feature Engineering\n",
      "Overview\n",
      "Feature selection\n",
      "Feature extraction\n",
      "Vector embedding\n",
      "Latent space\n",
      "Caret right\n",
      "Dimensionality reduction\n",
      "Principal component analysis\n",
      "Linear discriminant analysis\n",
      "Upsampling\n",
      "Downsampling\n",
      "Synthetic data\n",
      "Data leakage\n",
      "Caret right\n",
      "Supervised learning\n",
      "Overview\n",
      "Caret right\n",
      "Regression\n",
      "Linear regression\n",
      "Lasso regression\n",
      "Ridge regression\n",
      "State space model\n",
      "Time series\n",
      "Autoregressive model\n",
      "Caret right\n",
      "Classification\n",
      "Overview\n",
      "Decision trees\n",
      "K-nearest neighbors (KNNs)\n",
      "Naive bayes\n",
      "Random forest\n",
      "Support vector machine\n",
      "Logistic regression\n",
      "Caret right\n",
      "Ensemble learning\n",
      "Overview\n",
      "Boosting\n",
      "Bagging\n",
      "Gradient boosting\n",
      "Gradient boosting classifier\n",
      "Caret right\n",
      "Self-supervised learning\n",
      "Overview\n",
      "Transfer learning\n",
      "Caret right\n",
      "Unsupervised learning\n",
      "Overview\n",
      "Caret right\n",
      "Clustering\n",
      "Overview\n",
      "K means clustering\n",
      "Hierarchical clustering\n",
      "A priori algorithm\n",
      "Gaussian mixture model\n",
      "Anomaly detection\n",
      "Caret right\n",
      "Semi-supervised learning\n",
      "Overview\n",
      "Caret right\n",
      "Recommendation engine\n",
      "Collaborative filtering\n",
      "Content based filtering\n",
      "Caret right\n",
      "Reinforcement learning\n",
      "Overview\n",
      "Reinforcement learning human feedback\n",
      "Caret right\n",
      "Deep Learning\n",
      "Overview\n",
      "Caret right\n",
      "Neural networks\n",
      "Overview\n",
      "Backpropagation\n",
      "Encoder-decoder model\n",
      "Recurrent neural networks\n",
      "Long short-term memory (LSTM)\n",
      "Convolutional neural networks\n",
      "Caret right\n",
      "Transformer models\n",
      "Overview\n",
      "Attention mechanism\n",
      "Grouped query attention\n",
      "Positional encoding\n",
      "Autoencoder\n",
      "Mamba model\n",
      "Graph neural network\n",
      "Caret right\n",
      "Generative AI\n",
      "Overview\n",
      "Generative model\n",
      "Generative AI vs. predictive AI\n",
      "Caret right\n",
      "Large language models (LLMs)\n",
      "Overview\n",
      "Reasoning models\n",
      "Sma\n"
     ]
    }
   ],
   "source": [
    "celest = fetch_website_contents(\"https://www.ibm.com/think/topics/large-language-models/\")\n",
    "print(celest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f0d11",
   "metadata": {},
   "source": [
    "## Prompt types explained simply\n",
    "\n",
    "System prompt\n",
    "Defines who the model is and the rules it must follow\n",
    "Highest priority\n",
    "\n",
    "Developer prompt\n",
    "Adds app level behavior and formatting rules\n",
    "Second highest priority\n",
    "\n",
    "User prompt\n",
    "The actual question or task\n",
    "Can be constrained by system and developer\n",
    "\n",
    "Assistant prompt\n",
    "The model’s previous replies\n",
    "Used only for conversation context\n",
    "\n",
    "Tool prompt\n",
    "Tells the model when and how to use tools or functions\n",
    "Used for actions like math or API calls\n",
    "\n",
    "Priority order\n",
    "System → Developer → Tool → User → Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b11d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt\n",
    "system_prompt = \"\"\"\n",
    "You are a snarky assistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b82593c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc6875",
   "metadata": {},
   "source": [
    "**Messages (what they are)**\n",
    "\n",
    "`messages` is the **ordered list of conversation turns** you send to the model.\n",
    "Each item has a **role** and **content**.\n",
    "\n",
    "**Roles**\n",
    "\n",
    "* `system` sets identity and rules\n",
    "* `developer` sets app level behavior\n",
    "* `user` asks the task\n",
    "* `assistant` stores prior model replies\n",
    "* `tool` returns tool results\n",
    "\n",
    "**Why order matters**\n",
    "The model reads messages **top to bottom** and follows priority rules.\n",
    "\n",
    "**Minimal structure**\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"...\"},\n",
    "    {\"role\": \"developer\", \"content\": \"...\"},\n",
    "    {\"role\": \"user\", \"content\": \"...\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"...\"},\n",
    "    {\"role\": \"tool\", \"content\": \"...\"}\n",
    "]\n",
    "```\n",
    "\n",
    "**Mental model**\n",
    "Messages = conversation + rules + memory in one list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a68eb4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 + 2 equals 4.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4.1-nano\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43681cf0",
   "metadata": {},
   "source": [
    "Use webscraping function to give chatgpt a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6b5ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80cd36eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\nYou are a snarky assistant that analyzes the contents of a website,\\nand provides a short, snarky, humorous summary, ignoring text that might be navigation related.\\nRespond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': '\\nHere are the contents of a website.\\nProvide a short summary of this website.\\nIf it includes news or announcements, then summarize these too.\\n\\nWhat Are Large Language Models (LLMs)? | IBM \\n\\nWhat are large language models (LLMs)?\\nMachine learning\\nWelcome\\nCaret right\\nIntroduction\\nOverview\\nMachine learning types\\nMachine learning algorithms\\nCaret right\\nData science for machine learning\\nStatistical machine learning\\nLinear algebra for machine learning\\nUncertainty quantification\\nBias variance tradeoff\\nBayesian Statistics\\nCaret right\\nFeature Engineering\\nOverview\\nFeature selection\\nFeature extraction\\nVector embedding\\nLatent space\\nCaret right\\nDimensionality reduction\\nPrincipal component analysis\\nLinear discriminant analysis\\nUpsampling\\nDownsampling\\nSynthetic data\\nData leakage\\nCaret right\\nSupervised learning\\nOverview\\nCaret right\\nRegression\\nLinear regression\\nLasso regression\\nRidge regression\\nState space model\\nTime series\\nAutoregressive model\\nCaret right\\nClassification\\nOverview\\nDecision trees\\nK-nearest neighbors (KNNs)\\nNaive bayes\\nRandom forest\\nSupport vector machine\\nLogistic regression\\nCaret right\\nEnsemble learning\\nOverview\\nBoosting\\nBagging\\nGradient boosting\\nGradient boosting classifier\\nCaret right\\nSelf-supervised learning\\nOverview\\nTransfer learning\\nCaret right\\nUnsupervised learning\\nOverview\\nCaret right\\nClustering\\nOverview\\nK means clustering\\nHierarchical clustering\\nA priori algorithm\\nGaussian mixture model\\nAnomaly detection\\nCaret right\\nSemi-supervised learning\\nOverview\\nCaret right\\nRecommendation engine\\nCollaborative filtering\\nContent based filtering\\nCaret right\\nReinforcement learning\\nOverview\\nReinforcement learning human feedback\\nCaret right\\nDeep Learning\\nOverview\\nCaret right\\nNeural networks\\nOverview\\nBackpropagation\\nEncoder-decoder model\\nRecurrent neural networks\\nLong short-term memory (LSTM)\\nConvolutional neural networks\\nCaret right\\nTransformer models\\nOverview\\nAttention mechanism\\nGrouped query attention\\nPositional encoding\\nAutoencoder\\nMamba model\\nGraph neural network\\nCaret right\\nGenerative AI\\nOverview\\nGenerative model\\nGenerative AI vs. predictive AI\\nCaret right\\nLarge language models (LLMs)\\nOverview\\nReasoning models\\nSma'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try it out on previously scrapedw ebsite\n",
    "messages_for(celest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f10bbc9",
   "metadata": {},
   "source": [
    "merge it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "392cc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API.\n",
    "def summarize(url):\n",
    "    website = fetch_website_contents(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4.1-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2283f6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, the IBM guide to Large Language Models (LLMs), or as I like to call it, “Machine Learning for the Overachievers.” This site is basically a cornucopia of machine learning goodness, from baby steps like linear regression all the way to the rockstars: transformers, attention mechanisms, and generative AI. It’s like the ultimate nerd handbook—complete with every algorithm, trick, and buzzword you never knew you needed to memorize.\\n\\nNo exciting news or earth-shattering announcements here—just a meticulously organized laundry list of ML topics that quietly says, “If you’re not overwhelmed yet, just keep scrolling.” Perfect for folks who want to wander through the entire jungle of machine learning without ever leaving the page. In other words: textbook-level info served with an IBM polish and zero chill.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://www.ibm.com/think/topics/large-language-models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e66d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "751fed7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# IBM’s “What Are Large Language Models (LLMs)?” – The Ultimate Machine Learning Buffet\n",
       "\n",
       "Welcome to IBM’s sprawling encyclopedia where every corner is crammed with machine learning goodies—from the basics of regression to the wizardry of transformer models and generative AI. They basically threw every ML buzzword into one menu and called it a day.\n",
       "\n",
       "If you were looking for a juicy news or announcement, tough luck—this is purely an educational feast. No plot twists or scandalous AI gossip here, just a textbook-level deep dive so granular it probably gives your brain a workout.\n",
       "\n",
       "In short: If you want to know **everything** about machine learning and LLMs (like you’re planning to build the next ChatGPT in your basement), IBM has your back with chapters for days. If you want snappy news or dramatic AI updates... maybe check Twitter."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://www.ibm.com/think/topics/large-language-models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8394fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-And-Generative-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
